{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "jfLCShDyezRA",
        "K2KMpqi3ew0m",
        "lCI3pWoOXG9P",
        "mTqP4mjXS8jH"
      ],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be5uBRdgbhey"
      },
      "source": [
        "# DVC pipelines and model compression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Environment setup\n",
        "!rm -rf sample_data .config\n",
        "!git config --global user.email \"jane@doe.eu\"\n",
        "!git config --global user.name \"Jane Doe\"\n",
        "!git config --global init.defaultBranch main\n",
        "!pip install dvc dvclive --quiet\n",
        "!pip install -U uv"
      ],
      "metadata": {
        "id": "k8-GyNS0040Z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DVC & Git repositories setup"
      ],
      "metadata": {
        "id": "JaYoMWEw18bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize DVC & Git."
      ],
      "metadata": {
        "id": "AuEDNwplIgyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!# Your command here, note the ! that prefixes bash commands in Colab"
      ],
      "metadata": {
        "id": "YjxrOQYYe05N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "jfLCShDyezRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "id": "F7XxyudA2BCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc init"
      ],
      "metadata": {
        "id": "WGveKO6p2LvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Initialization of DVC and Git\""
      ],
      "metadata": {
        "id": "ZtFe7jvjWrSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding the data to DVC"
      ],
      "metadata": {
        "id": "eHg1bYoR3E69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With [`dvc import-url`](https://dvc.org/doc/command-reference/import-url), download the following zip that we are going to use:\n",
        "\n",
        "    https://github.com/shuuchuu/dataset-landscape/archive/refs/heads/main.zip\n",
        "\n",
        "Use `data.zip` as output name."
      ],
      "metadata": {
        "id": "hRqA6DmmIz2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!# Your command here, note the ! that prefixes bash commands in Colab"
      ],
      "metadata": {
        "id": "jRephhgv2Qex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commit the changes to `git`."
      ],
      "metadata": {
        "id": "FUm4ZbxVXCGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "K2KMpqi3ew0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc import-url https://github.com/shuuchuu/dataset-landscape/archive/refs/heads/main.zip data.zip"
      ],
      "metadata": {
        "id": "u7Nw0yKceyLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .gitignore data.zip.dvc"
      ],
      "metadata": {
        "id": "aHxjp14nW4BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Add data\""
      ],
      "metadata": {
        "id": "X1zJcQQEW8Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5hheTPDcdqN"
      },
      "source": [
        "## Create a pipeline step to extract the contents of the zip archive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With `dvc stage add`, or by editing the `dvc.yaml` file, create a dvc pipeline step to extract the files from `data.zip` (to do so, you can use `unzip`)."
      ],
      "metadata": {
        "id": "1LY9vBJbJZHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!# Your command here, note the ! that prefixes bash commands in Colab"
      ],
      "metadata": {
        "id": "zgLSiKHHXGj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "lCI3pWoOXG9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc stage add -n decompress -d data.zip -o dataset-landscape-main unzip data.zip"
      ],
      "metadata": {
        "id": "hJ0Gy6-cXIDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc repro"
      ],
      "metadata": {
        "id": "DhvBdxmfXi-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add dvc.lock dvc.yaml .gitignore"
      ],
      "metadata": {
        "id": "wG-josUZXz7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Add extraction step\""
      ],
      "metadata": {
        "id": "Evniv5p1X4kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python project setup"
      ],
      "metadata": {
        "id": "5-CM-HtMS5gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup a python project or python file to be able to run your source code easily."
      ],
      "metadata": {
        "id": "oiD-caJxYoZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!# Your command here, note the ! that prefixes bash commands in Colab"
      ],
      "metadata": {
        "id": "4P6W2CwDYk7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "mTqP4mjXS8jH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run `uv init --package --name compression .` to create `pyproject.toml`\n",
        "2. Create source folder and `__init__.py` in it\n",
        "3. Add an entrypoint:\n",
        "        [project.scripts]\n",
        "        commandname = \"folder.file:function\"\n",
        "4. Run `uv sync`\n",
        "6. `!commandname`"
      ],
      "metadata": {
        "id": "NN_fXK4xYhQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv init --package --name compression ."
      ],
      "metadata": {
        "id": "6Prox45thWf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/compression/__init__.py\n",
        "def main() -> None:\n",
        "    print(\"Hello World\")"
      ],
      "metadata": {
        "id": "AKBczN0AYZCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv sync"
      ],
      "metadata": {
        "id": "sFh9B7qwYL6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv run compression"
      ],
      "metadata": {
        "id": "uPFoYrxcYSYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zCSZcuhczAn"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "To prepare data before training and compressing the model, we are going to use the following function, that you can incorporate into your codebase as you see fit:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data preparation code\n",
        "import pathlib\n",
        "\n",
        "import cv2\n",
        "import numpy\n",
        "import sklearn.metrics\n",
        "import sklearn.utils\n",
        "\n",
        "CLASS_NAMES = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "CLASS_INDICES = {l: i for i, l in enumerate(CLASS_NAMES)}\n",
        "\n",
        "\n",
        "def get_images(\n",
        "    dir_path: pathlib.Path, image_size: tuple[int, int], shuffle: bool = True\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
        "    images = []\n",
        "    labels = []\n",
        "    file_paths = []\n",
        "\n",
        "    for subdir_path in dir_path.iterdir():\n",
        "\n",
        "        label = CLASS_INDICES.get(subdir_path.name)\n",
        "\n",
        "        for image_path in subdir_path.iterdir():\n",
        "            image = cv2.imread(str(image_path))\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, image_size)\n",
        "            image = image.astype(\"float32\")\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "            file_paths.append(image_path)\n",
        "    images_array = numpy.array(images)\n",
        "    labels_array = numpy.array(labels)\n",
        "    file_paths_array = numpy.array(file_paths)\n",
        "\n",
        "    if shuffle:\n",
        "        images_array, labels_array, file_paths_array = sklearn.utils.shuffle(\n",
        "            images_array, labels_array, file_paths_array\n",
        "        )\n",
        "    return images_array, labels_array, file_paths_array\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "G2HPZIzXLsng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a simple model"
      ],
      "metadata": {
        "id": "zL4up166KYjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now going to train a simple classification model (and historical one at that): LeNet. You can incorporate the code below to your project as you see fit."
      ],
      "metadata": {
        "id": "dREoPa6bnjiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model definition code\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_lenet(\n",
        "    image_size: tuple[int, int], learning_rate: float = 1e-4\n",
        ") -> tf.keras.models.Model:\n",
        "    def conv(filters: int, padding: str) -> tf.keras.layers.Conv2D:\n",
        "        return tf.keras.layers.Conv2D(\n",
        "            filters=filters, kernel_size=5, padding=padding, activation=\"sigmoid\"\n",
        "        )\n",
        "\n",
        "    def pooling() -> tf.keras.layers.MaxPooling2D:\n",
        "        return tf.keras.layers.MaxPooling2D()\n",
        "\n",
        "    def dense(units: int, activation: str = \"sigmoid\") -> tf.keras.layers.Dense:\n",
        "        return tf.keras.layers.Dense(units, activation=activation)\n",
        "\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(*image_size, 3)),\n",
        "            conv(6, \"same\"),\n",
        "            pooling(),\n",
        "            conv(16, \"valid\"),\n",
        "            pooling(),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            dense(120),\n",
        "            dense(84),\n",
        "            dense(6, activation=\"softmax\"),\n",
        "        ],\n",
        "        name=\"le_net\",\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a61ILhe6L89d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model training code\n",
        "from pathlib import Path\n",
        "\n",
        "from ... import get_images  # To edit depending on your code organization\n",
        "from ... import get_lenet  # To edit depending on your code organization\n",
        "\n",
        "\n",
        "def train(\n",
        "    data_dir: str,\n",
        "    image_size: tuple[int, int],\n",
        "    learning_rate: float,\n",
        ") -> None:\n",
        "    images, labels, paths = get_images(Path(data_dir), image_size)\n",
        "    model = get_lenet(image_size, learning_rate)\n",
        "    model.fit(images, labels, 128, epochs=3)\n",
        "    model.save(\"landscape_classifier.keras\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cAuEKzSxMfyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline step definition"
      ],
      "metadata": {
        "id": "faiu3cL_oLSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now define a pipeline step to train a model."
      ],
      "metadata": {
        "id": "bt-GwtrbWj3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!# Your command here, note the ! that prefixes bash commands in Colab"
      ],
      "metadata": {
        "id": "Jey-W1YqhidV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc repro"
      ],
      "metadata": {
        "id": "UNLpPjhlfGHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-training model compression"
      ],
      "metadata": {
        "id": "78tmBphSLK4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can follow this [guide](https://www.tensorflow.org/model_optimization/guide/quantization/post_training) to add a compression step to your training. Check the model performances after quantization."
      ],
      "metadata": {
        "id": "zz88vb6oLQUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!# Your command here, note the ! that prefixes bash commands in Colab"
      ],
      "metadata": {
        "id": "p1OkOIxtsS0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc repro"
      ],
      "metadata": {
        "id": "TjPSg3XpuB3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "t4QwJ-J-Lgru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/shuuchuu/compression"
      ],
      "metadata": {
        "id": "FG3xYk3aLh3_"
      }
    }
  ]
}